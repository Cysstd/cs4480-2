# python_analysis_fixed_json.py - ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜çš„ç‰ˆæœ¬

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score
import time
import json
import warnings
import os
import multiprocessing as mp
from joblib import Parallel, delayed
from datetime import datetime
import subprocess
warnings.filterwarnings('ignore')

# åŠ¨æ€å¯¼å…¥å¯é€‰ä¾èµ–
try:
    from xgboost import XGBClassifier
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

# å¿…éœ€çš„æœºå™¨å­¦ä¹ æ¨¡å‹
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier

class FixedJSONMLAnalysis:
    def __init__(self):
        self.results = []
        self.parallel_results = {}
        self.models_config = {}
        self.data_info = {}
        
        # å›ºå®šçš„HDFSè·¯å¾„ - å¿…é¡»ä»è¿™é‡Œè·å–çœŸå®æ•°æ®
        self.hdfs_path = "/user/hadoop/image_analysis/extracted_features_final"
        
        # å›ºå®šçš„æ ¸å¿ƒé…ç½® - ç”¨æˆ·è¦æ±‚çš„æ€§èƒ½æµ‹è¯•
        self.core_configs = [1, 2, 4, 6]
        
        print("ğŸ”§ é…ç½®ä¿¡æ¯:")
        print(f"   HDFSè·¯å¾„: {self.hdfs_path}")
        print(f"   æµ‹è¯•æ ¸å¿ƒ: {self.core_configs}")
    
    def convert_numpy_types(self, obj):
        """é€’å½’è½¬æ¢NumPyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œè§£å†³JSONåºåˆ—åŒ–é—®é¢˜"""
        if isinstance(obj, (np.integer, np.int32, np.int64)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float32, np.float64)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {self.convert_numpy_types(k): self.convert_numpy_types(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [self.convert_numpy_types(item) for item in obj]
        else:
            return obj
    
    def validate_hdfs_connection(self):
        """éªŒè¯HDFSè¿æ¥å’Œæ•°æ®å­˜åœ¨"""
        print("ğŸ”— éªŒè¯HDFSè¿æ¥...")
        
        try:
            # æ£€æŸ¥HDFSæœåŠ¡æ˜¯å¦è¿è¡Œ
            check_hdfs = subprocess.run(["hdfs", "dfsadmin", "-report"], 
                                      capture_output=True, text=True, timeout=10)
            if check_hdfs.returncode != 0:
                raise Exception(f"HDFSæœåŠ¡ä¸å¯ç”¨: {check_hdfs.stderr}")
            
            print("âœ… HDFSæœåŠ¡è¿è¡Œæ­£å¸¸")
            
            # æ£€æŸ¥ç‰¹å¾æ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨
            check_path = subprocess.run(["hdfs", "dfs", "-test", "-e", self.hdfs_path], 
                                      capture_output=True)
            if check_path.returncode != 0:
                raise Exception(f"HDFSè·¯å¾„ä¸å­˜åœ¨: {self.hdfs_path}")
            
            print("âœ… HDFSç‰¹å¾æ•°æ®è·¯å¾„å­˜åœ¨")
            
            # æ£€æŸ¥è·¯å¾„ä¸‹æ˜¯å¦æœ‰æ•°æ®æ–‡ä»¶
            check_files = subprocess.run(["hdfs", "dfs", "-count", self.hdfs_path], 
                                       capture_output=True, text=True)
            if check_files.returncode == 0:
                file_count = check_files.stdout.strip().split()[1]
                print(f"âœ… HDFSæ•°æ®æ–‡ä»¶æ•°: {file_count}")
            else:
                raise Exception("æ— æ³•ç»Ÿè®¡HDFSæ–‡ä»¶")
                
            return True
            
        except subprocess.TimeoutExpired:
            raise Exception("HDFSè¿æ¥è¶…æ—¶")
        except Exception as e:
            raise Exception(f"HDFSéªŒè¯å¤±è´¥: {e}")
    
    def load_real_data_from_hdfs(self):
        """ä»HDFSåŠ è½½çœŸå®çš„Sparkç‰¹å¾æ•°æ®"""
        print("ğŸ“ ä»HDFSåŠ è½½çœŸå®ç‰¹å¾æ•°æ®...")
        print(f"ğŸ“‚ æ•°æ®è·¯å¾„: {self.hdfs_path}")
        
        try:
            # æ‰§è¡ŒHDFSå‘½ä»¤è·å–æ•°æ®
            cmd = ["hdfs", "dfs", "-cat", f"{self.hdfs_path}/part-*"]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode != 0:
                raise Exception(f"HDFSæ•°æ®è¯»å–å¤±è´¥: {result.stderr}")
            
            lines = result.stdout.strip().split('\n')
            if not lines or lines[0] == '':
                raise Exception("HDFSæ•°æ®ä¸ºç©º")
            
            print(f"âœ… æˆåŠŸè¯»å– {len(lines)} è¡ŒçœŸå®æ•°æ®")
            
            return self._parse_real_spark_data(lines)
            
        except subprocess.TimeoutExpired:
            raise Exception("HDFSæ•°æ®è¯»å–è¶…æ—¶")
        except Exception as e:
            raise Exception(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
    
    def _parse_real_spark_data(self, lines):
        """è§£æçœŸå®çš„Sparkç‰¹å¾æ•°æ®"""
        print("ğŸ” è§£æçœŸå®Sparkç‰¹å¾æ•°æ®...")
        
        features_list = []
        labels_list = []
        valid_count = 0
        error_count = 0
        
        for i, line in enumerate(lines):
            try:
                data = json.loads(line.strip())
                features = data.get('image_features', [])
                label = data.get('label', -1)
                
                # ä¸¥æ ¼éªŒè¯æ•°æ®æ ¼å¼
                if (features and 
                    label in [0, 1] and  # å¿…é¡»æ˜¯0æˆ–1
                    len(features) > 10 and  # ç‰¹å¾æ•°é‡å¿…é¡»åˆç†
                    isinstance(features, list)):
                    
                    features_list.append(features)
                    labels_list.append(label)
                    valid_count += 1
                else:
                    error_count += 1
                    
            except (json.JSONDecodeError, TypeError) as e:
                error_count += 1
                if i < 3:  # åªæ˜¾ç¤ºå‰å‡ ä¸ªé”™è¯¯çš„è¯¦ç»†ä¿¡æ¯
                    print(f"   âš ï¸ æ•°æ®è§£æé”™è¯¯è¡Œ {i}: {e}")
        
        print(f"ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š:")
        print(f"   âœ… æœ‰æ•ˆæ•°æ®: {valid_count} è¡Œ")
        print(f"   âŒ æ— æ•ˆæ•°æ®: {error_count} è¡Œ")
        print(f"   ğŸ“ˆ æ•°æ®è´¨é‡: {valid_count/(valid_count+error_count)*100:.1f}%")
        
        if valid_count == 0:
            raise Exception("æ²¡æœ‰æœ‰æ•ˆçš„ç‰¹å¾æ•°æ®ï¼Œè¯·æ£€æŸ¥Sparkç‰¹å¾æå–æ˜¯å¦æ­£ç¡®è¿è¡Œ")
        
        if valid_count < 10:
            print("âš ï¸  è­¦å‘Š: æœ‰æ•ˆæ•°æ®é‡è¾ƒå°‘ï¼Œå¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½")
        
        X = np.array(features_list)
        y = np.array(labels_list)
        
        # æ•°æ®ç»Ÿè®¡ä¿¡æ¯ - ç¡®ä¿ä½¿ç”¨PythonåŸç”Ÿç±»å‹
        class_dist = dict(zip(*np.unique(y, return_counts=True)))
        class_dist_native = {int(k): int(v) for k, v in class_dist.items()}  # è½¬æ¢ä¸ºåŸç”Ÿç±»å‹
        
        self.data_info = {
            'samples': int(X.shape[0]),  # è½¬æ¢ä¸ºint
            'features': int(X.shape[1]),  # è½¬æ¢ä¸ºint
            'class_distribution': class_dist_native,  # ä½¿ç”¨è½¬æ¢åçš„å­—å…¸
            'feature_range': [float(X.min()), float(X.max())],  # è½¬æ¢ä¸ºfloat
            'feature_mean': float(X.mean()),  # è½¬æ¢ä¸ºfloat
            'data_source': 'Spark_HDFS_Real_Data',
            'load_time': datetime.now().isoformat()
        }
        
        print(f"ğŸ¯ çœŸå®æ•°æ®ç»´åº¦: {X.shape[0]} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")
        print(f"ğŸ“Š ç±»åˆ«åˆ†å¸ƒ: {self.data_info['class_distribution']}")
        print(f"ğŸ“ˆ ç‰¹å¾èŒƒå›´: [{self.data_info['feature_range'][0]:.2f}, {self.data_info['feature_range'][1]:.2f}]")
        print(f"ğŸ“ˆ ç‰¹å¾å‡å€¼: {self.data_info['feature_mean']:.2f}")
        
        return X, y
    
    def prepare_models(self):
        """å‡†å¤‡æœºå™¨å­¦ä¹ æ¨¡å‹ - ä¿æŒåŸæœ‰é…ç½®"""
        print("ğŸ¤– åˆå§‹åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹...")
        
        # ä¿æŒåŸæœ‰çš„æ¨¡å‹é…ç½®
        self.models_config = {
            'Random Forest': {
                'model': RandomForestClassifier(n_estimators=100, random_state=42),
                'needs_scaling': False
            },
            'Logistic Regression': {
                'model': LogisticRegression(max_iter=1000, random_state=42),
                'needs_scaling': True
            },
            'Decision Tree': {
                'model': DecisionTreeClassifier(random_state=42),
                'needs_scaling': False
            },
            'SVM': {
                'model': SVC(probability=True, random_state=42),
                'needs_scaling': True
            },
            'Naive Bayes': {
                'model': GaussianNB(),
                'needs_scaling': False
            },
            'K-Neighbors': {
                'model': KNeighborsClassifier(n_neighbors=5),
                'needs_scaling': True
            },
            'Neural Network': {
                'model': MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42),
                'needs_scaling': True
            }
        }
        
        # å¦‚æœXGBoostå¯ç”¨ï¼Œæ·»åŠ å®ƒ
        if XGBOOST_AVAILABLE:
            self.models_config['XGBoost'] = {
                'model': XGBClassifier(n_estimators=100, random_state=42, verbosity=0),
                'needs_scaling': False
            }
            print("   âœ… XGBoost")
        else:
            print("   âŒ XGBoost (ä¸å¯ç”¨)")
        
        print(f"âœ… åˆå§‹åŒ–äº† {len(self.models_config)} ä¸ªæ¨¡å‹")
        return self.models_config
    
    def train_single_model(self, model_name, model_config, X_train, X_test, y_train, y_test):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        try:
            model = model_config['model']
            needs_scaling = model_config['needs_scaling']
            start_time = time.time()
            
            # è®­ç»ƒæ¨¡å‹
            if needs_scaling:
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            else:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            
            training_time = time.time() - start_time
            
            # è¯„ä¼°æ¨¡å‹
            accuracy = accuracy_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred, average='weighted')
            
            return {
                'model_name': model_name,
                'accuracy': float(accuracy),  # è½¬æ¢ä¸ºfloat
                'f1_score': float(f1),  # è½¬æ¢ä¸ºfloat
                'training_time': float(training_time),  # è½¬æ¢ä¸ºfloat
                'success': True
            }
            
        except Exception as e:
            print(f"âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}")
            return {
                'model_name': model_name,
                'accuracy': 0.0,
                'f1_score': 0.0,
                'training_time': 0.0,
                'success': False,
                'error': str(e)
            }
    
    def run_sequential_training(self, X, y):
        """é¡ºåºè®­ç»ƒï¼ˆå•æ ¸å¿ƒåŸºå‡†ï¼‰"""
        print("ğŸ”¢ é¡ºåºè®­ç»ƒï¼ˆå•æ ¸å¿ƒåŸºå‡†ï¼‰...")
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        
        results = []
        total_start = time.time()
        
        for model_name, model_config in self.models_config.items():
            result = self.train_single_model(
                model_name, model_config, X_train, X_test, y_train, y_test
            )
            results.append(result)
            
            if result['success']:
                print(f"   âœ… {model_name}: å‡†ç¡®ç‡={result['accuracy']:.4f}, æ—¶é—´={result['training_time']:.2f}s")
        
        total_time = time.time() - total_start
        
        return {
            'results': results,
            'total_time': float(total_time),  # è½¬æ¢ä¸ºfloat
            'cores': 1,
            'method': 'sequential'
        }
    
    def run_parallel_training(self, X, y, n_cores):
        """å¹¶è¡Œè®­ç»ƒ"""
        print(f"ğŸ”„ å¹¶è¡Œè®­ç»ƒ ({n_cores} æ ¸å¿ƒ)...")
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        
        total_start = time.time()
        
        # å¹¶è¡Œè®­ç»ƒæ‰€æœ‰æ¨¡å‹
        parallel_results = Parallel(n_jobs=n_cores)(
            delayed(self.train_single_model)(
                model_name, model_config, X_train, X_test, y_train, y_test
            )
            for model_name, model_config in self.models_config.items()
        )
        
        total_time = time.time() - total_start
        
        # æ˜¾ç¤ºç»“æœ
        for result in parallel_results:
            if result['success']:
                print(f"   âœ… {result['model_name']}: å‡†ç¡®ç‡={result['accuracy']:.4f}")
        
        return {
            'results': parallel_results,
            'total_time': float(total_time),  # è½¬æ¢ä¸ºfloat
            'cores': n_cores,
            'method': f'parallel_{n_cores}cores'
        }
    
    def run_core_performance_comparison(self, X, y):
        """è¿è¡Œæ ¸å¿ƒæ•°æ€§èƒ½æ¯”è¾ƒ"""
        print("âš¡ å¼€å§‹å¤šæ ¸å¿ƒæ€§èƒ½æ¯”è¾ƒ...")
        print("=" * 60)
        
        # ä½¿ç”¨å›ºå®šçš„æ ¸å¿ƒé…ç½®
        max_system_cores = mp.cpu_count()
        actual_cores = [c for c in self.core_configs if c <= max_system_cores]
        
        print(f"ğŸ’» ç³»ç»Ÿæœ€å¤§æ ¸å¿ƒæ•°: {max_system_cores}")
        print(f"ğŸ”§ å®é™…æµ‹è¯•æ ¸å¿ƒ: {actual_cores}")
        
        if not actual_cores:
            raise Exception(f"ç³»ç»Ÿåªæœ‰ {max_system_cores} æ ¸å¿ƒï¼Œæ— æ³•æµ‹è¯•é…ç½® {self.core_configs}")
        
        comparison_results = {}
        
        for n_cores in actual_cores:
            print(f"\nğŸ¯ æµ‹è¯• {n_cores} æ ¸å¿ƒæ€§èƒ½...")
            
            if n_cores == 1:
                result = self.run_sequential_training(X, y)
            else:
                result = self.run_parallel_training(X, y, n_cores)
            
            comparison_results[f'{n_cores}_cores'] = result
            
            # æ€§èƒ½æ‘˜è¦
            successful_models = [r for r in result['results'] if r['success']]
            if successful_models:
                avg_accuracy = np.mean([r['accuracy'] for r in successful_models])
                print(f"   ğŸ“Š å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.4f}")
                print(f"   â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {result['total_time']:.2f}s")
        
        self.parallel_results = comparison_results
        return comparison_results
    
    def calculate_performance_metrics(self):
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        print("\nğŸ“ˆ è®¡ç®—æ€§èƒ½æŒ‡æ ‡...")
        
        if not self.parallel_results:
            return None
        
        sequential_result = self.parallel_results.get('1_cores')
        if not sequential_result:
            return None
        
        sequential_time = sequential_result['total_time']
        metrics = {}
        
        for config, result in self.parallel_results.items():
            if config == '1_cores':
                metrics[config] = {
                    'speedup': 1.0,
                    'efficiency': 1.0,
                    'total_time': float(result['total_time'])  # è½¬æ¢ä¸ºfloat
                }
            else:
                parallel_time = result['total_time']
                n_cores = result['cores']
                speedup = sequential_time / parallel_time if parallel_time > 0 else 1.0
                efficiency = speedup / n_cores
                
                metrics[config] = {
                    'speedup': float(speedup),  # è½¬æ¢ä¸ºfloat
                    'efficiency': float(efficiency),  # è½¬æ¢ä¸ºfloat
                    'total_time': float(parallel_time)  # è½¬æ¢ä¸ºfloat
                }
        
        return metrics
    
    def create_performance_visualizations(self, performance_metrics):
        """åˆ›å»ºæ€§èƒ½å¯è§†åŒ–"""
        print("\nğŸ¨ ç”Ÿæˆæ€§èƒ½å¯è§†åŒ–å›¾è¡¨...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('çœŸå®æ•°æ® - Pythonå¹¶è¡Œæœºå™¨å­¦ä¹ æ€§èƒ½åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. æ¨¡å‹å‡†ç¡®ç‡æ¯”è¾ƒ
        if self.parallel_results:
            sequential_results = self.parallel_results.get('1_cores', {}).get('results', [])
            successful_models = [r for r in sequential_results if r['success']]
            
            if successful_models:
                model_names = [r['model_name'] for r in successful_models]
                accuracies = [r['accuracy'] for r in successful_models]
                
                bars = axes[0, 0].bar(model_names, accuracies, color='skyblue', alpha=0.7)
                axes[0, 0].set_title('æ¨¡å‹å‡†ç¡®ç‡æ¯”è¾ƒ (çœŸå®æ•°æ®)')
                axes[0, 0].set_ylabel('å‡†ç¡®ç‡')
                axes[0, 0].tick_params(axis='x', rotation=45)
                
                # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
                for bar, accuracy in zip(bars, accuracies):
                    height = bar.get_height()
                    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                                   f'{accuracy:.3f}', ha='center', va='bottom', fontsize=8)
        
        # 2. å¹¶è¡ŒåŠ é€Ÿæ¯”
        if performance_metrics:
            configs = list(performance_metrics.keys())
            speedups = [metrics['speedup'] for metrics in performance_metrics.values()]
            
            bars = axes[0, 1].bar(configs, speedups, color='lightgreen', alpha=0.7)
            axes[0, 1].set_title('å¹¶è¡ŒåŠ é€Ÿæ¯”')
            axes[0, 1].set_ylabel('åŠ é€Ÿæ¯” (å€æ•°)')
            axes[0, 1].tick_params(axis='x', rotation=45)
            
            for bar, speedup in zip(bars, speedups):
                height = bar.get_height()
                axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.1,
                               f'{speedup:.2f}x', ha='center', va='bottom')
        
        # 3. è®­ç»ƒæ—¶é—´æ¯”è¾ƒ
        if self.parallel_results:
            configs = list(self.parallel_results.keys())
            times = [result['total_time'] for result in self.parallel_results.values()]
            
            bars = axes[1, 0].bar(configs, times, color='lightcoral', alpha=0.7)
            axes[1, 0].set_title('æ€»è®­ç»ƒæ—¶é—´æ¯”è¾ƒ')
            axes[1, 0].set_ylabel('æ—¶é—´ (ç§’)')
            axes[1, 0].tick_params(axis='x', rotation=45)
            
            for bar, time_val in zip(bars, times):
                height = bar.get_height()
                axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.1,
                               f'{time_val:.1f}s', ha='center', va='bottom', fontsize=8)
        
        # 4. æ•°æ®ä¿¡æ¯å’Œé…ç½®
        info_text = f"æ•°æ®ä¿¡æ¯:\n"
        info_text += f"æ¥æº: {self.data_info['data_source']}\n"
        info_text += f"æ ·æœ¬æ•°: {self.data_info['samples']}\n"
        info_text += f"ç‰¹å¾æ•°: {self.data_info['features']}\n"
        info_text += f"ç±»åˆ«åˆ†å¸ƒ: {self.data_info['class_distribution']}\n"
        info_text += f"ç‰¹å¾èŒƒå›´: [{self.data_info['feature_range'][0]:.1f}, {self.data_info['feature_range'][1]:.1f}]\n\n"
        info_text += f"é…ç½®ä¿¡æ¯:\n"
        info_text += f"æµ‹è¯•æ ¸å¿ƒ: {self.core_configs}\n"
        info_text += f"æ¨¡å‹æ•°é‡: {len(self.models_config)}\n"
        info_text += f"æ•°æ®è·¯å¾„: {self.hdfs_path}"
        
        axes[1, 1].text(0.05, 0.95, info_text, fontsize=9, va='top', linespacing=1.5)
        axes[1, 1].set_title('æ•°æ®å’Œé…ç½®ä¿¡æ¯')
        axes[1, 1].axis('off')
        
        plt.tight_layout()
        plt.savefig('real_data_performance_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… æ€§èƒ½å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: real_data_performance_analysis.png")
    
    def save_real_data_results(self):
        """ä¿å­˜çœŸå®æ•°æ®çš„ç»“æœ - ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜"""
        print("\nğŸ’¾ ä¿å­˜çœŸå®æ•°æ®åˆ†æç»“æœ...")
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs('real_data_results', exist_ok=True)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        performance_metrics = self.calculate_performance_metrics()
        
        # å‡†å¤‡ç»“æœæ•°æ®ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®ç±»å‹éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
        results_data = {
            'analysis_info': {
                'timestamp': datetime.now().isoformat(),
                'data_source': 'Spark_HDFS_Real_Data',
                'hdfs_path': self.hdfs_path,
                'core_configs': self.core_configs
            },
            'data_info': self.data_info,  # å·²ç»åœ¨åˆå§‹åŒ–æ—¶è½¬æ¢ä¸ºåŸç”Ÿç±»å‹
            'parallel_results': self.convert_numpy_types(self.parallel_results),  # é€’å½’è½¬æ¢
            'performance_metrics': self.convert_numpy_types(performance_metrics)  # é€’å½’è½¬æ¢
        }
        
        # ä¿å­˜JSONç»“æœ
        results_path = 'real_data_results/real_data_analysis.json'
        try:
            with open(results_path, 'w') as f:
                json.dump(results_data, f, indent=2, ensure_ascii=False)
            print(f"âœ… JSONç»“æœå·²ä¿å­˜: {results_path}")
        except Exception as e:
            print(f"âŒ JSONä¿å­˜å¤±è´¥: {e}")
            # å°è¯•ç®€åŒ–ä¿å­˜
            self._save_simplified_results()
            return
        
        # ä¿å­˜CSVæ ¼å¼çš„ç»“æœ
        if self.parallel_results:
            all_results = []
            for config, result in self.parallel_results.items():
                for model_result in result['results']:
                    if model_result['success']:
                        all_results.append({
                            'config': config,
                            'model': model_result['model_name'],
                            'accuracy': float(model_result['accuracy']),
                            'f1_score': float(model_result['f1_score']),
                            'training_time': float(model_result['training_time'])
                        })
            
            df = pd.DataFrame(all_results)
            csv_path = 'real_data_results/model_performance.csv'
            df.to_csv(csv_path, index=False)
            print(f"âœ… CSVç»“æœå·²ä¿å­˜: {csv_path}")
        
        print("âœ… æ‰€æœ‰ç»“æœæ–‡ä»¶ä¿å­˜å®Œæˆ!")
    
    def _save_simplified_results(self):
        """ç®€åŒ–ä¿å­˜ç»“æœï¼Œç¡®ä¿ä¸€å®šèƒ½ä¿å­˜"""
        print("ğŸ”„ å°è¯•ç®€åŒ–ä¿å­˜ç»“æœ...")
        
        simplified_data = {
            'timestamp': datetime.now().isoformat(),
            'data_samples': self.data_info['samples'],
            'data_features': self.data_info['features'],
            'data_source': self.data_info['data_source'],
            'models_tested': list(self.models_config.keys())
        }
        
        # ä¿å­˜æ ¸å¿ƒæ€§èƒ½ç»“æœ
        if self.parallel_results:
            performance_summary = {}
            for config, result in self.parallel_results.items():
                successful_models = [r for r in result['results'] if r['success']]
                if successful_models:
                    avg_accuracy = float(np.mean([r['accuracy'] for r in successful_models]))
                    performance_summary[config] = {
                        'avg_accuracy': avg_accuracy,
                        'total_time': float(result['total_time']),
                        'successful_models': len(successful_models)
                    }
            
            simplified_data['performance_summary'] = performance_summary
        
        # ä¿å­˜ç®€åŒ–ç»“æœ
        simple_path = 'real_data_results/simplified_results.json'
        with open(simple_path, 'w') as f:
            json.dump(simplified_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ç®€åŒ–ç»“æœå·²ä¿å­˜: {simple_path}")
    
    def print_final_summary(self):
        """æ‰“å°æœ€ç»ˆæ€»ç»“"""
        print("\n" + "="*60)
        print("ğŸ† çœŸå®æ•°æ®åˆ†ææ€»ç»“")
        print("="*60)
        
        print(f"ğŸ“Š æ•°æ®ä¿¡æ¯:")
        print(f"   æ•°æ®æ¥æº: {self.data_info['data_source']}")
        print(f"   HDFSè·¯å¾„: {self.hdfs_path}")
        print(f"   æ ·æœ¬æ•°é‡: {self.data_info['samples']}")
        print(f"   ç‰¹å¾ç»´åº¦: {self.data_info['features']}")
        print(f"   ç±»åˆ«åˆ†å¸ƒ: {self.data_info['class_distribution']}")
        
        # æ€§èƒ½æ€»ç»“
        metrics = self.calculate_performance_metrics()
        if metrics:
            print(f"\nâš¡ æ€§èƒ½æ€»ç»“:")
            best_config = max([(k, v) for k, v in metrics.items() if k != '1_cores'], 
                            key=lambda x: x[1]['speedup'], default=None)
            if best_config:
                print(f"   æœ€ä½³å¹¶è¡Œé…ç½®: {best_config[0]}")
                print(f"   åŠ é€Ÿæ¯”: {best_config[1]['speedup']:.2f}x")
                print(f"   å¹¶è¡Œæ•ˆç‡: {best_config[1]['efficiency']:.2f}")
            
            sequential_time = metrics.get('1_cores', {}).get('total_time', 0)
            print(f"   é¡ºåºè®­ç»ƒæ—¶é—´: {sequential_time:.2f}s")
        
        # æœ€ä½³æ¨¡å‹
        if self.parallel_results:
            sequential_results = self.parallel_results.get('1_cores', {}).get('results', [])
            successful_models = [r for r in sequential_results if r['success']]
            if successful_models:
                best_model = max(successful_models, key=lambda x: x['accuracy'])
                print(f"\nğŸ¯ æœ€ä½³æ¨¡å‹: {best_model['model_name']}")
                print(f"   å‡†ç¡®ç‡: {best_model['accuracy']:.4f}")
                print(f"   F1åˆ†æ•°: {best_model['f1_score']:.4f}")
                print(f"   è®­ç»ƒæ—¶é—´: {best_model['training_time']:.2f}s")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ çœŸå®æ•°æ®Pythonå¹¶è¡Œæœºå™¨å­¦ä¹ åˆ†æ (ä¿®å¤JSONç‰ˆæœ¬)")
    print("=" * 60)
    print("ğŸ’¡ æ­¤ç‰ˆæœ¬ä¿®å¤äº†JSONåºåˆ—åŒ–é—®é¢˜ï¼Œå¼ºåˆ¶ä½¿ç”¨çœŸå®Sparkç‰¹å¾æ•°æ®")
    print("=" * 60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = FixedJSONMLAnalysis()
    
    try:
        # 1. éªŒè¯HDFSè¿æ¥
        analyzer.validate_hdfs_connection()
        
        # 2. åŠ è½½çœŸå®æ•°æ®
        X, y = analyzer.load_real_data_from_hdfs()
        
        # 3. å‡†å¤‡æ¨¡å‹
        analyzer.prepare_models()
        
        # 4. è¿è¡Œæ ¸å¿ƒæ€§èƒ½æ¯”è¾ƒ
        analyzer.run_core_performance_comparison(X, y)
        
        # 5. è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        performance_metrics = analyzer.calculate_performance_metrics()
        
        # 6. åˆ›å»ºå¯è§†åŒ–
        analyzer.create_performance_visualizations(performance_metrics)
        
        # 7. ä¿å­˜ç»“æœ
        analyzer.save_real_data_results()
        
        # 8. æ‰“å°æ€»ç»“
        analyzer.print_final_summary()
        
        print("\nâœ… çœŸå®æ•°æ®åˆ†æå®Œæˆ!")
        print("ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨ 'real_data_results/' ç›®å½•ä¸­")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿:")
        print("   1. HadoopæœåŠ¡æ­£åœ¨è¿è¡Œ")
        print("   2. Sparkç‰¹å¾æå–å·²å®Œæˆ")
        print("   3. HDFSè·¯å¾„å­˜åœ¨: /user/hadoop/image_analysis/extracted_features_final")
        raise

if __name__ == "__main__":
    main()