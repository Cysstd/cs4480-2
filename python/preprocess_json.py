# preprocess_json_fixed.py - JSONæ ¼å¼é¢„å¤„ç†

import json
import os
import subprocess

def preprocess_json_for_pig():
    """ä¸ºPigå¤„ç†å‡†å¤‡JSONæ•°æ®"""
    print("ğŸ”„ å¼€å§‹å‡†å¤‡Pigå¤„ç†æ•°æ®...")
    
    input_path = "/user/hadoop/image_analysis/image_metadata.json"
    output_path = "/user/hadoop/image_analysis/image_metadata_line_by_line.json"
    
    try:
        # ä»HDFSä¸‹è½½åŸå§‹JSON
        print("ğŸ“¥ ä»HDFSä¸‹è½½åŸå§‹JSON...")
        download_result = subprocess.run(
            ["hdfs", "dfs", "-cat", input_path], 
            capture_output=True, text=True, check=True
        )
        
        # è§£æJSONæ•°æ®
        print("ğŸ” è§£æJSONæ•°æ®...")
        data = json.loads(download_result.stdout)
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(data)} æ¡è®°å½•")
        
        # è½¬æ¢ä¸ºæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
        print("ğŸ“ è½¬æ¢ä¸ºæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡...")
        with open('temp_line_by_line.json', 'w', encoding='utf-8') as f:
            for item in data:
                json_line = json.dumps(item, ensure_ascii=False)
                f.write(json_line + '\n')
        
        # ä¸Šä¼ åˆ°HDFS
        print("â¬†ï¸ ä¸Šä¼ åˆ°HDFS...")
        subprocess.run([
            "hdfs", "dfs", "-put", "-f", "temp_line_by_line.json", output_path
        ], check=True)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists('temp_line_by_line.json'):
            os.remove('temp_line_by_line.json')
        
        print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ HDFSæ“ä½œå¤±è´¥: {e}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = preprocess_json_for_pig()
    if not success:
        print("âŒ é¢„å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥HDFSå’ŒJSONæ–‡ä»¶")
        exit(1)